{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDuZQ4f-Kuc1"
      },
      "source": [
        "# Fundamentos de Apache Spark: SQL/DataFrames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_5_ZKViKuc9"
      },
      "source": [
        "**Spark SQLtrabaja con DataFrames**. Un DataFrame es una **representación relacional de los datos**. Proporciona funciones con capacidades similares a SQL. Además, permite escribir **consultas tipo SQL** para nuestro análisis de datos.\n",
        "\n",
        "Los DataFrames son similares a las tablas relacionales o DataFrames en Python / R auqnue con muchas optimizaciones que se ejecutan de manera \"oculta\" para el usuario."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install findspark\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "qT4eAP9iFiQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRMXLIztKuc_"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "import pandas as pd\n",
        "import pyspark\n",
        "import zipfile\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSnvTJmlKudB"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwD3q5VxKudB"
      },
      "source": [
        "### Crear la sesión de Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVdbvXb6KudC"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYlAo59fKudZ"
      },
      "source": [
        "### Crea un DataFrame a partir de un archivo CSV\n",
        "* Podemos crear un DataFrame usando un archivo CSV y podemos especificar varias opciones como un separador, encabezado, esquema, inferSchema y varias otras opciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epTTPlXLKudZ"
      },
      "outputs": [],
      "source": [
        "df = spark.read.csv(\"path_to_csv_file\", sep=\"|\", header=True, inferSchema=True)\n",
        "#PANDAS\n",
        "df = pd.read_csv('ejemplo1.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ez7JXGETKudC"
      },
      "source": [
        "### Crear el DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vtLCdlOKudD"
      },
      "outputs": [],
      "source": [
        "#LISTA\n",
        "emp = [(1, \"AAA\", \"dept1\", 1000),\n",
        "    (2, \"BBB\", \"dept1\", 1100),\n",
        "    (3, \"CCC\", \"dept1\", 3000),\n",
        "    (4, \"DDD\", \"dept1\", 1500),\n",
        "    (5, \"EEE\", \"dept2\", 8000),\n",
        "    (6, \"FFF\", \"dept2\", 7200),\n",
        "    (7, \"GGG\", \"dept3\", 7100),\n",
        "    (8, \"HHH\", \"dept3\", 3700),\n",
        "    (9, \"III\", \"dept3\", 4500),\n",
        "    (10, \"JJJ\", \"dept5\", 3400)]\n",
        "\n",
        "dept = [(\"dept1\", \"Department - 1\"),\n",
        "        (\"dept2\", \"Department - 2\"),\n",
        "        (\"dept3\", \"Department - 3\"),\n",
        "        (\"dept4\", \"Department - 4\")\n",
        "\n",
        "       ]\n",
        "\n",
        "#PANDAS\n",
        "#emp_df = pd.DataFrame(emp, columns=[\"id\", \"name\", \"dept\", \"salary\"])\n",
        "#dept_df = pd.DataFrame(dept, columns=[\"id\", \"name\"])\n",
        "\n",
        "#PYSPARK\n",
        "df = spark.createDataFrame(emp, [\"id\", \"name\", \"dept\", \"salary\"])\n",
        "\n",
        "deptdf = spark.createDataFrame(dept, [\"id\", \"name\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4E8gxad3KudE",
        "outputId": "9134e794-2cab-4676-9ded-3e1b06a6cd19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+-----+------+\n",
            "| id|name| dept|salary|\n",
            "+---+----+-----+------+\n",
            "|  1| AAA|dept1|  1000|\n",
            "|  2| BBB|dept1|  1100|\n",
            "|  3| CCC|dept1|  3000|\n",
            "|  4| DDD|dept1|  1500|\n",
            "|  5| EEE|dept2|  8000|\n",
            "|  6| FFF|dept2|  7200|\n",
            "|  7| GGG|dept3|  7100|\n",
            "|  8| HHH|dept3|  3700|\n",
            "|  9| III|dept3|  4500|\n",
            "| 10| JJJ|dept5|  3400|\n",
            "+---+----+-----+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show()\n",
        "\n",
        "#PANDAS\n",
        "#df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVHBuHEBKudG"
      },
      "source": [
        "# Operaciones básicas en DataFrames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3lFfJT_KudG"
      },
      "source": [
        "### count\n",
        "* Cuenta el número de filas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMvVanwwKudG",
        "outputId": "a5b028aa-f14d-4ea4-af97-dcb3d024e9bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "df.count()\n",
        "\n",
        "#PANDAS\n",
        "#len(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_EUGg9gKudH"
      },
      "source": [
        "### columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFbfK2_vKudH",
        "outputId": "6ee81ac2-e3a6-4167-b443-df73049582c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['id', 'name', 'dept', 'salary']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns\n",
        "\n",
        "#PANDAS\n",
        "#df.columns.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmkMq2c7KudH"
      },
      "source": [
        "### dtypes\n",
        "** Accede al DataType de columnas dentro del DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MGVyDM1KudI",
        "outputId": "fc0e642d-59f6-492a-d188-801a2aefde53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('id', 'bigint'),\n",
              " ('name', 'string'),\n",
              " ('dept', 'string'),\n",
              " ('salary', 'bigint')]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.dtypes\n",
        "#="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_36ARwUKudI"
      },
      "source": [
        "##schema\n",
        "Comprueba cómo Spark almacena el esquema del DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHdAlQe-KudI",
        "outputId": "605779c1-e35a-48c8-aa63-96153ff0129a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructType([StructField('id', LongType(), True), StructField('name', StringType(), True), StructField('dept', StringType(), True), StructField('salary', LongType(), True)])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "df.schema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzH8ceBoKudJ"
      },
      "source": [
        "### printSchema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCrBuEFfKudJ",
        "outputId": "16a1474a-9d41-4c60-9e00-ff1d07c5d872",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- dept: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()\n",
        "\n",
        "#PANDAS\n",
        "#df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJcYHpjcKudJ"
      },
      "source": [
        "### select\n",
        "* Seleccione columnas del DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MJbriyHKudJ",
        "outputId": "f2756664-11fb-4030-bd57-84551ea713fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----+\n",
            "| id|name|\n",
            "+---+----+\n",
            "|  1| AAA|\n",
            "|  2| BBB|\n",
            "|  3| CCC|\n",
            "|  4| DDD|\n",
            "|  5| EEE|\n",
            "|  6| FFF|\n",
            "|  7| GGG|\n",
            "|  8| HHH|\n",
            "|  9| III|\n",
            "| 10| JJJ|\n",
            "+---+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.select(\"id\", \"name\").show()\n",
        "\n",
        "#PANDAS\n",
        "#df[[\"id\", \"name\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuB4wujnKudK"
      },
      "source": [
        "### filter\n",
        "\n",
        "* Filtrar las filas según alguna condición.\n",
        "* Intentemos encontrar las filas con id = 1.\n",
        "* Hay diferentes formas de especificar la condición."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geArrMVkKudK",
        "outputId": "afd7bfa3-89ba-4def-d055-32fccfe65920"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----+-----+------+\n",
            "| id|name| dept|salary|\n",
            "+---+----+-----+------+\n",
            "|  1| AAA|dept1|  1000|\n",
            "+---+----+-----+------+\n",
            "\n",
            "+---+----+-----+------+\n",
            "| id|name| dept|salary|\n",
            "+---+----+-----+------+\n",
            "|  1| AAA|dept1|  1000|\n",
            "+---+----+-----+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.filter(df[\"id\"] == 1).show()\n",
        "df.filter(df.id == 1).show()\n",
        "\n",
        "#PANDAS\n",
        "#df[df[\"id\"] == 1]\n",
        "#df[df.id == 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Om_ebmqbKudK",
        "outputId": "ff3ef14d-5ce4-4a16-886f-cb76690fe26e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----+-----+------+\n",
            "| id|name| dept|salary|\n",
            "+---+----+-----+------+\n",
            "|  1| AAA|dept1|  1000|\n",
            "+---+----+-----+------+\n",
            "\n",
            "+---+----+-----+------+\n",
            "| id|name| dept|salary|\n",
            "+---+----+-----+------+\n",
            "|  1| AAA|dept1|  1000|\n",
            "+---+----+-----+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.filter(col(\"id\") == 1).show()\n",
        "df.filter(\"id = 1\").show()\n",
        "\n",
        "#PANDAS\n",
        "#df[df[\"id\"] == 1]\n",
        "#df.query(\"id == 1\")\n",
        "#SQL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maRZaqZDKudK"
      },
      "source": [
        "### drop\n",
        "* Elimina una columna en particular"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-BmrBrGKudL",
        "outputId": "66fbf728-08f3-426a-f9d9-2914b158d145"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+-----+------+\n",
            "|name| dept|salary|\n",
            "+----+-----+------+\n",
            "| AAA|dept1|  1000|\n",
            "| BBB|dept1|  1100|\n",
            "+----+-----+------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "newdf = df.drop(\"id\")\n",
        "newdf.show(2)\n",
        "\n",
        "#PANDAS\n",
        "#newdf = df.drop(\"id\", axis=1)\n",
        "#newdf.head(2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyRonPfeKudM"
      },
      "source": [
        "### Sorting\n",
        "\n",
        "* Ordena los datos según el \"salario\". De forma predeterminada, la clasificación se realizará en orden ascendente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgLvpat9KudM",
        "outputId": "d41aeb8d-97fd-4e6a-a3eb-e39451096642"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----+-----+------+\n",
            "| id|name| dept|salary|\n",
            "+---+----+-----+------+\n",
            "|  1| AAA|dept1|  1000|\n",
            "|  2| BBB|dept1|  1100|\n",
            "|  4| DDD|dept1|  1500|\n",
            "|  3| CCC|dept1|  3000|\n",
            "| 10| JJJ|dept5|  3400|\n",
            "+---+----+-----+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.sort(\"salary\").show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDgVzHQUKudM",
        "outputId": "fcb1bbb8-74d5-4b01-f87d-ccdfada79267"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----+-----+------+\n",
            "| id|name| dept|salary|\n",
            "+---+----+-----+------+\n",
            "|  5| EEE|dept2|  8000|\n",
            "|  6| FFF|dept2|  7200|\n",
            "|  7| GGG|dept3|  7100|\n",
            "|  9| III|dept3|  4500|\n",
            "|  8| HHH|dept3|  3700|\n",
            "+---+----+-----+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Sort the data in descending order.\n",
        "df.sort(desc(\"salary\")).show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwl7P5ibKudM"
      },
      "source": [
        "### Columnas derivadas\n",
        "* Podemos usar la función \"withColumn\" para derivar la columna en función de las columnas existentes ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSEdUq1vKudN",
        "outputId": "b9b6f148-6180-47cd-ee28-579ee2fee21b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----+-----+------+-----+\n",
            "| id|name| dept|salary|bonus|\n",
            "+---+----+-----+------+-----+\n",
            "|  1| AAA|dept1|  1000|100.0|\n",
            "|  2| BBB|dept1|  1100|110.0|\n",
            "|  3| CCC|dept1|  3000|300.0|\n",
            "|  4| DDD|dept1|  1500|150.0|\n",
            "|  5| EEE|dept2|  8000|800.0|\n",
            "|  6| FFF|dept2|  7200|720.0|\n",
            "|  7| GGG|dept3|  7100|710.0|\n",
            "|  8| HHH|dept3|  3700|370.0|\n",
            "|  9| III|dept3|  4500|450.0|\n",
            "| 10| JJJ|dept5|  3400|340.0|\n",
            "+---+----+-----+------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.withColumn(\"bonus\", col(\"salary\") * .1).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4KfuB-NKudN"
      },
      "source": [
        "### Joins\n",
        "\n",
        "* Podemos realizar varios tipos de combinaciones en múltiples DataFrames (interseccion)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6Z-fHDnKudN",
        "outputId": "5842c09b-c3d5-49c5-dc61-d8dd7c84d7ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----+-----+------+-----+--------------+\n",
            "| id|name| dept|salary|   id|          name|\n",
            "+---+----+-----+------+-----+--------------+\n",
            "|  7| GGG|dept3|  7100|dept3|Department - 3|\n",
            "|  8| HHH|dept3|  3700|dept3|Department - 3|\n",
            "|  9| III|dept3|  4500|dept3|Department - 3|\n",
            "|  1| AAA|dept1|  1000|dept1|Department - 1|\n",
            "|  2| BBB|dept1|  1100|dept1|Department - 1|\n",
            "|  3| CCC|dept1|  3000|dept1|Department - 1|\n",
            "|  4| DDD|dept1|  1500|dept1|Department - 1|\n",
            "|  5| EEE|dept2|  8000|dept2|Department - 2|\n",
            "|  6| FFF|dept2|  7200|dept2|Department - 2|\n",
            "+---+----+-----+------+-----+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Inner JOIN.\n",
        "df.join(deptdf, df[\"dept\"] == deptdf[\"id\"]).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sWEloExKudO"
      },
      "source": [
        "### Left Outer Join (izq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEQGHDUoKudV",
        "outputId": "95788f05-bc43-4677-a7fa-a05efe0c1e74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----+-----+------+-----+--------------+\n",
            "| id|name| dept|salary|   id|          name|\n",
            "+---+----+-----+------+-----+--------------+\n",
            "| 10| JJJ|dept5|  3400| null|          null|\n",
            "|  7| GGG|dept3|  7100|dept3|Department - 3|\n",
            "|  8| HHH|dept3|  3700|dept3|Department - 3|\n",
            "|  9| III|dept3|  4500|dept3|Department - 3|\n",
            "|  1| AAA|dept1|  1000|dept1|Department - 1|\n",
            "|  2| BBB|dept1|  1100|dept1|Department - 1|\n",
            "|  3| CCC|dept1|  3000|dept1|Department - 1|\n",
            "|  4| DDD|dept1|  1500|dept1|Department - 1|\n",
            "|  5| EEE|dept2|  8000|dept2|Department - 2|\n",
            "|  6| FFF|dept2|  7200|dept2|Department - 2|\n",
            "+---+----+-----+------+-----+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.join(deptdf, df[\"dept\"] == deptdf[\"id\"], \"left_outer\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dubae8fmKudV"
      },
      "source": [
        "### Right Outer Join (der)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oz4Brfg8KudV",
        "outputId": "f1f573c6-a899-47b6-d716-745a7667185c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+----+-----+------+-----+--------------+\n",
            "|  id|name| dept|salary|   id|          name|\n",
            "+----+----+-----+------+-----+--------------+\n",
            "|   7| GGG|dept3|  7100|dept3|Department - 3|\n",
            "|   8| HHH|dept3|  3700|dept3|Department - 3|\n",
            "|   9| III|dept3|  4500|dept3|Department - 3|\n",
            "|   1| AAA|dept1|  1000|dept1|Department - 1|\n",
            "|   2| BBB|dept1|  1100|dept1|Department - 1|\n",
            "|   3| CCC|dept1|  3000|dept1|Department - 1|\n",
            "|   4| DDD|dept1|  1500|dept1|Department - 1|\n",
            "|null|null| null|  null|dept4|Department - 4|\n",
            "|   5| EEE|dept2|  8000|dept2|Department - 2|\n",
            "|   6| FFF|dept2|  7200|dept2|Department - 2|\n",
            "+----+----+-----+------+-----+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.join(deptdf, df[\"dept\"] == deptdf[\"id\"], \"right_outer\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nP_WNdiaKudW"
      },
      "source": [
        "### Full Outer Join"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrWPCGLzKudW",
        "outputId": "70af1d52-93c2-4838-ebb9-587d42475e48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+----+-----+------+-----+--------------+\n",
            "|  id|name| dept|salary|   id|          name|\n",
            "+----+----+-----+------+-----+--------------+\n",
            "|  10| JJJ|dept5|  3400| null|          null|\n",
            "|   7| GGG|dept3|  7100|dept3|Department - 3|\n",
            "|   8| HHH|dept3|  3700|dept3|Department - 3|\n",
            "|   9| III|dept3|  4500|dept3|Department - 3|\n",
            "|   1| AAA|dept1|  1000|dept1|Department - 1|\n",
            "|   2| BBB|dept1|  1100|dept1|Department - 1|\n",
            "|   3| CCC|dept1|  3000|dept1|Department - 1|\n",
            "|   4| DDD|dept1|  1500|dept1|Department - 1|\n",
            "|null|null| null|  null|dept4|Department - 4|\n",
            "|   5| EEE|dept2|  8000|dept2|Department - 2|\n",
            "|   6| FFF|dept2|  7200|dept2|Department - 2|\n",
            "+----+----+-----+------+-----+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.join(deptdf, df[\"dept\"] == deptdf[\"id\"], \"outer\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQxbPblyKudW"
      },
      "source": [
        "### Consultas SQL\n",
        "* Ejecución de consultas tipo SQL.\n",
        "* También podemos realizar análisis de datos escribiendo consultas similares a SQL. Para realizar consultas similares a SQL, necesitamos registrar el DataFrame como una Vista temporal.\n",
        "* Persiste con la Sparksession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-BXHKLyKudX",
        "outputId": "6fc14f4d-1894-4e48-d75b-edb29c6d9715",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+-----+------+\n",
            "| id|name| dept|salary|\n",
            "+---+----+-----+------+\n",
            "|  1| AAA|dept1|  1000|\n",
            "+---+----+-----+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Register DataFrame as Temporary Table\n",
        "df.createOrReplaceTempView(\"temp_table\")\n",
        "\n",
        "# Execute SQL-Like query.\n",
        "spark.sql(\"select * from temp_table where id = 1\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdTTnkSGKudX",
        "outputId": "381c82f1-d8c9-4bb7-af3b-77c0653a8011"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+\n",
            "| id|\n",
            "+---+\n",
            "|  7|\n",
            "|  6|\n",
            "|  9|\n",
            "|  5|\n",
            "|  1|\n",
            "| 10|\n",
            "|  3|\n",
            "|  8|\n",
            "|  2|\n",
            "|  4|\n",
            "+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"select distinct id from temp_table\").show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZNJZPgMKudX",
        "outputId": "03e4f163-7a72-44ed-b0f7-a7cd4c85eb5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----+-----+------+\n",
            "| id|name| dept|salary|\n",
            "+---+----+-----+------+\n",
            "|  3| CCC|dept1|  3000|\n",
            "|  4| DDD|dept1|  1500|\n",
            "|  5| EEE|dept2|  8000|\n",
            "|  6| FFF|dept2|  7200|\n",
            "|  7| GGG|dept3|  7100|\n",
            "|  8| HHH|dept3|  3700|\n",
            "|  9| III|dept3|  4500|\n",
            "| 10| JJJ|dept5|  3400|\n",
            "+---+----+-----+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"select * from temp_table where salary >= 1500\").show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3YlbeCyKuda"
      },
      "source": [
        "### Guardar un DataFrame como un archivo CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeHTW4swKuda"
      },
      "outputs": [],
      "source": [
        "df.write.csv(\"path_to_CSV_File\", sep=\"|\", header=True, mode=\"overwrite\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}